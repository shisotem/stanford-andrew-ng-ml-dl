# Gradient descent in practice

## Feature scaling part 1

- **Feature scaling** will enable gradient descent to run much **faster**.

- When a possible range of values of a **feature** is **large**, it's more likely that a good model will learn to choose a relatively **small parameter** value. Likewise, when the possible values of the **feature** are **small**, then a reasonable value for its **parameters** will be relatively **large**.

  ![alt text](resources/notes/01.png)

## Feature scaling part 2

## Checking gradient descent for convergence

## Choosing the learning rate

## Optional Lab: Feature scaling and learning rate

## Feature engineering

## Polynomial regression

## Optional lab: Feature engineering and Polynomial regression

## Optional lab: Linear regression with scikit-learn
