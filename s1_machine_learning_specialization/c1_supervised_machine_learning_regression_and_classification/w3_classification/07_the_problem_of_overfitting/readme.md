# The problem of overfitting

## The problem of overfitting

- **Underfit** = **High bias** ↔ Just right = Generalization ↔ **Overfit** = **High variance**

  - Underfitting: Caused by **preconception** or strong bias, like assuming data is linear.

  - **Generalization**: Ability to predict accurately on unseen examples.

  - Overfitting: Occurs with **high-order polynomials** with **many features**.

    - Parameters make cost function zero (error is zero for all training examples).

    - **Works well on training set, but not on new examples**.

    - Slight changes in training set drastically alter the applied function.

  ![alt text](resources/notes/01.png)

  ![alt text](resources/notes/02.png)

- Q:

  ![alt text](resources/questions/01.png)

## Addressing overfitting

- a

  ![alt text](resources/notes/03.png)

  ![alt text](resources/notes/04.png)

  ![alt text](resources/notes/05.png)

  ![alt text](resources/notes/06.png)

- Q:

  ![alt text](resources/questions/02.png)

## Optional lab: Overfitting

## Cost function with regularization

- a

- Q:

## Regularized linear regression

- a

- Q:

## Regularized logistic regression

- a

- Q:

## Optional lab: Regularization
