# Vectorization (optional)

## How neural networks are implemented efficiently

- Not only does GPU excel at large **matrix multiplications**, but some CPU functions, such as `np.matmul`, are also very efficient at this task.

  ![alt text](resources/notes/01.png)

## Matrix multiplication

- **The dot product of vectors 'a' and 'w'** is equivalent to **the multiplication of the transposed vector 'a' with vector 'w'**.

  ![alt text](resources/notes/02.png)

## Matrix multiplication rules

## Matrix multiplication code
